pipeline {
    agent any
    
    parameters {
        gitParameter name: 'BRANCH_TAG', 
                     type: 'PT_BRANCH_TAG',
                     defaultValue: 'master'
    }
    
    
      environment {
     
        git_url = 'https://github.com/wintel-co-th/kafka-mfec-testcase.git'
        // AZURE RESOURCE
        AcrRegistry = 'wintelhub.azurecr.io'                        // acrth01seanshared01
        AcrRegistry_prod  = 'acrth01seapshared01'


        AZ_AKZ_USER = 'azure-chaiyapon'
        AZ_AKS_RESOUCE_GROUP = 'AKS-Cluster'
        
	 // AZURE AKS Cluster
        az_cluster_name = 'wintel'
        NAMESPACE = 'kafka'  
	
        // Kafka Cluster
        kafka_cluster_name = 'thdlcd3-uat-kafka-cluster'
	kafka_bootstrap_name = 'kafka-bootstrap.thdlcd3-uat.aiaazure.biz'
	
        // Kafka connect
        kafka_connect_name = 'thdlcd3-uat-connect-cluster'	
	
       	//Kafka bridge 

        kafak_bridge_ingres = 'kafka-bridge-thdlcd3-uat.aiaazure.biz'
	
	// authentication
	user_kafka = 'chaiyapon'
	
	// IP edge Node
	
	edge_ip = '20.205.169.228'
	
	

    }

  
    stages {
    
    
           stage('Azure Login'){
            steps {

                 withCredentials([azureServicePrincipal('azure-chaiyapon')]) {
                  sh 'az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET -t $AZURE_TENANT_ID' 
                  sh 'az account show'
            }
       }
    }
         
    
           stage('Get credentials Azure AKS'){
            steps {
                     
                     //cleanup current user k8s credentials
                    sh 'rm -rf   ~/.kube || true'
                    sh "echo ============ AKS Credential ==============="
                    sh "az aks get-credentials -n ${az_cluster_name} -g ${AZ_AKS_RESOUCE_GROUP}"
            }      
       }
    
   
		
		  stage('GitClone') {
              steps {
                script {
                    def scmInfo = checkout([
                        $class: 'GitSCM',
                        branches: [[name: '${BRANCH_TAG}']],
                        doGenerateSubmoduleConfigurations: false,
                        extensions: [],
                        submoduleCfg: [],
                        userRemoteConfigs: [
                            [credentialsId: 'git_credentials',
                            url: env.git_url]
                        ]
                    ])
                    
                }
            }
        }
	
	
	
        
        
       stage('2.1: Testing Down Kafka Cluster') {
             steps {
                
                  // capture Before Down
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  // Down kafk-0
                 /// sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i kafka-0) -n ${NAMESPACE} || true'
                  // Pod are terminating and createing 
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  ///sh 'sleep 5m'
                  // Verify kafka-o up and running
                   sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
  
  
   stage('2.2: Load Data to Topic') {
             steps {
                
                  // copy scrip insert 
                 sh 'kubectl cp 2.2/insert.sh  ${kafka_cluster_name}-kafka-0:/home/kafka  -n ${NAMESPACE}'
                 sh 'kubectl cp 2.2/file01  ${kafka_cluster_name}-kafka-0:/home/kafka  -n ${NAMESPACE}'
                 sh 'kubectl exec ${kafka_cluster_name}-kafka-0  /home/kafka/insert.sh  -n ${NAMESPACE}'


            }
        }
  
  
   stage('2.3: Consumer Data from Topic') {
             steps {
                
                  // Consumer
      sh 'kubectl exec ${kafka_cluster_name}-kafka-0  -n ${NAMESPACE} -- bin/kafka-console-consumer.sh --bootstrap-server  localhost:9092  --topic topic-a --from-beginning --timeout-ms 10000'

            }
        }
  
  
     stage('3.1: Testing Down Zookeeper Cluster') {
             steps {
                
                  // capture Before Down
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  // Down zookeeper-0
                  sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i zookeeper-0) -n ${NAMESPACE} || true'
                  // Pod are terminating and createing 
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  sh 'sleep 5m'
                  // Verify zookeeper-0 up and running
                  sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
  
     stage('4.1: Testing Client API Connect to Kafka bridge') {
             steps {
                
                  // list ingress
                  sh 'kubectl get ingress -n ${NAMESPACE} '
                  // list kafka bridge
                  sh 'kubectl get pods -n ${NAMESPACE} | grep -i bridge'
                  // healthy check kafka bridge  
                  sh 'curl -v GET http://${kafak_bridge_ingres}/healthy'
          
            }
        }





        
   stage('5.1.1: Testing Connecter Load Data to JDBC Connect') {
             steps {
                
                  // List connector
                  sh 'kubectl get kctr -n ${NAMESPACE} '
                 // replace env
                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  5.1/jdbc/kafka-jdbc.yaml|| true"
                 sh "sed -i 's|my_connect_cluster|${kafka_connect_name}|g'  5.1/jdbc/kafka-jdbc.yaml|| true"
                 sh "sed -i 's|ip_edge|${edge_ip}|g'  5.1/jdbc/kafka-jdbc.yaml|| true"
                 sh "cat  5.1/jdbc/kafka-jdbc.yaml|| true"
                 //  create JDBC connector
                 sh 'kubectl apply -f 5.1/jdbc/kafka-jdbc.yaml|| true'
                 sh 'sleep 5m'
                // verify jdbc connector
                 sh 'kubectl get kctr -n ${NAMESPACE} '
                  

            }
        }
  
     stage('5.1.2: Testing Connecter Load Data to File Connect') {
             steps {
                
                  // List connector
                  sh 'kubectl get kctr -n ${NAMESPACE} '
                   // replace env
                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  5.1/file/file-topic.yaml|| true"
                 sh "sed -i 's|kafka-cluster|${kafka_cluster_name}|g' 5.1/file/file-topic.yaml|| true"
                 sh 'kubectl apply -f  5.1/file/file-topic.yaml|| true'
      
      
                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/' 5.1/file/kafka-file.yaml|| true"
                 sh "sed -i 's|my_connect_cluster|${kafka_connect_name}|g'  5.1/file/kafka-file.yaml|| true"
                 sh "cat  5.1/file/kafka-file.yaml|| true"
                  //  create File connector
                  sh 'kubectl apply -f 5.1/file/kafka-file.yaml|| true'
                  sh 'sleep 5m'
                  // verify File connector
                  sh 'kubectl get kctr -n ${NAMESPACE} '
                  
                  
            }
        }
  
   stage('5.1.3: Testing Connecter Load Data to CSV File') {
             steps {
                
                  // List connector
                  sh 'kubectl get kctr -n ${NAMESPACE} '
                  // replace env
                  sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  5.1/csv/csv-topic.yaml|| true"
                  sh "sed -i 's|kafka-cluster|${kafka_cluster_name}|g'  5.1/csv/csv-topic.yaml|| true"
                  sh 'kubectl apply -f 5.1/csv/csv-topic.yaml|| true|| true'
      
                  sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/' 5.1/csv/kafka-csv.yaml|| true"
                  sh "sed -i 's|my_connect_cluster|${kafka_connect_name}|g' 5.1/csv/kafka-csv.yaml|| true"
                  sh "sed -i 's|ip_edge|${edge_ip}|g'  5.1/csv/kafka-csv.yaml|| true"
                  sh "cat  5.1/csv/kafka-csv.yaml|| true"
                  //  create csv connector
                  sh 'kubectl apply -f 5.1/csv/kafka-csv.yaml|| true'
                  sh 'sleep 5m'
                  // verify csv connector
                  sh 'kubectl get kctr -n ${NAMESPACE} '
                  

            }
        }
        
  
  
     stage('6.1: Testing Create Topic customer') {
             steps {
                
                  // list topic
                  sh 'kubectl get kt -n ${NAMESPACE} '
                  // create simple topic 
                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  6.1/customer-topic.yaml"
                 sh "sed -i 's|my-cluster|${kafka_cluster_name}|g'  examples/bridge/kafka-bridge-aia.yaml"
                 sh 'kubectl  apply -f  6.1/customer-topic.yaml'   
                 // check topic customer
                 sh 'kubectl get kt -n ${NAMESPACE} |grep -i customer '
            
            }
        }

    
  
  
     stage('6.2: Testing Create User') {
             steps {
                
                // list  user
                 sh 'kubectl get ku -n ${NAMESPACE} '
                // create user 
                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  6.2/kafka-user.yaml"
                 sh "sed -i 's|my-cluster|${kafka_cluster_name}|g'  6.2/kafka-user.yaml"
                 sh "sed -i 's|my-user|${user_kafka}|g'  6.2/kafka-user.yaml"
                 sh 'kubectl apply -f  6.2/kafka-user.yaml || true'
                 //sh 'sleep 2m'
                 // check user 
                 sh 'kubectl get ku -n ${NAMESPACE}'
    
    
            
            }
        }
  
  
     stage('6.3: Testing Kafka User  auth https/ssl') {
             steps {
                
                // Check  user chaiyapon with tls already exist
                 sh 'kubectl get ku -n ${NAMESPACE} '
               // Extract and configure the user credentials
                 sh "sed -i 's|my_user|${user_kafka}|g' kafka_user_auth.sh"
                 sh "sed -i 's|my_cluster|${kafka_cluster_name}|g' kafka_user_auth.sh"
                 sh "sed -i 's|kafka_nemspaces|${NAMESPACE}|g' kafka_user_auth.sh"
                 sh "sed -i 's|kafka_bootstrap|${kafka_bootstrap_name}|g' kafka_user_auth.sh"
                 sh 'sh kafka_user_auth.sh'
  
            }
        }
        
        
    

        

        
 
        
        

        
       
       
        
    }
   
}
      
