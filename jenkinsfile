pipeline {
    agent any
    
    parameters {
        gitParameter name: 'BRANCH_TAG', 
                     type: 'PT_BRANCH_TAG',
                     defaultValue: 'master'
    }
    
    
      environment {
     
        git_url = 'https://github.com/wintel-co-th/kafka-uat-cd-mfec.git'
        // AZURE RESOURCE
        AcrRegistry = 'wintelhub.azurecr.io'                        // acrth01seanshared01
        AcrRegistry_prod  = 'acrth01seapshared01'


        AZ_AKZ_USER = 'azure-chaiyapon'
        AZ_AKS_RESOUCE_GROUP = 'AKS-Cluster'
        
	 // AZURE AKS Cluster
        az_cluster_name = 'wintel'
        NAMESPACE = 'kafka'  
	
        // Kafka Cluster
        kafka_cluster_name = 'thdlcd0-uat-kafka-cluster'
	kafk_bootstrap_name = 'kafka-bootstrap.thdlcd01-uat.aiaazure.biz'
	
       	//Kafka bridge 

        kafak_bridge_ingres = 'kafka-bridge-thdlcd01-uat.aiaazure.biz'
	
	// authentication
	user_kafka = 'chaiyapon'
	
	

    }

  
    stages {
    
    
           stage('Azure Login'){
            steps {

                 withCredentials([azureServicePrincipal('azure-chaiyapon')]) {
                  sh 'az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET -t $AZURE_TENANT_ID' 
                  sh 'az account show'
            }
       }
    }
         
    
           stage('Get credentials Azure AKS'){
            steps {
                     
                     //cleanup current user k8s credentials
                    sh 'rm -rf   ~/.kube || true'
                    sh "echo ============ AKS Credential ==============="
                    sh "az aks get-credentials -n ${az_cluster_name} -g ${AZ_AKS_RESOUCE_GROUP}"
            }      
       }
    
   
		
		  stage('GitClone') {
              steps {
                script {
                    def scmInfo = checkout([
                        $class: 'GitSCM',
                        branches: [[name: '${BRANCH_TAG}']],
                        doGenerateSubmoduleConfigurations: false,
                        extensions: [],
                        submoduleCfg: [],
                        userRemoteConfigs: [
                            [credentialsId: 'git_credentials',
                            url: env.git_url]
                        ]
                    ])
                    
                }
            }
        }
		
		 stage('2.1: Testing Down Kafka Cluster') {
             steps {
	              
                  // capture Before Down
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  // Down kafk-0
                  sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i kafka-0) || true'
                  // Pod are terminating and createing 
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  sh 'sleep 5m'
                  // Verify kafka-o up and running
                   sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
        
        
    	 stage('2.1: Testing Down Kafka Cluster') {
             steps {
	              
                  // capture Before Down
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  // Down kafk-0
                  sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i kafka-0) || true'
                  // Pod are terminating and createing 
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  sh 'sleep 5m'
                  // Verify kafka-o up and running
                   sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
	
	
	 stage('2.2: Load Data to Topic') {
             steps {
	              
                  // copy scrip insert 
		  sh 'kubcetl cp 2.2/insert.sh  ${kafka_cluster_name}-kafka-0:/home/kafka  -n ${NAMESPACE}'
		  sh 'kubcetl cp 2.2/file01  ${kafka_cluster_name}-kafka-0:/home/kafka  -n ${NAMESPACE}'
		  sh 'kubectl exec ${kafka_cluster_name}-kafka-0  /home/kafka/insert.sh  -n ${NAMESPACE}'


            }
        }
	
	
	 stage('2.3: Consumer Data from Topic') {
             steps {
	              
                  // Consumer
		  sh 'kubectl exec ${kafka_cluster_name}-kafka-0  -n ${NAMESPACE} -- bin/kafka-console-consumer.sh --bootstrap-server  localhost:9092  --topic topic-a --from-beginning --timeout-ms 10000'

            }
        }
	
	
		 stage('3.1: Testing Down Zookeeper Cluster') {
             steps {
	              
                  // capture Before Down
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  // Down zookeeper-0
                  sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i zookeeper-0) || true'
                  // Pod are terminating and createing 
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  sh 'sleep 5m'
                  // Verify zookeeper-0 up and running
                  sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
	
		 stage('4.1: Testing Client API Connect to Kafka bridge') {
             steps {
	              
                  // list ingress
                  sh 'kubectl get ingress -n ${NAMESPACE} '
		  // list kafka bridge
		  sh 'kubectl get pods -n ${NAMESPACE} | grep -i bridge'
		  // healthy check kafka bridge  
		  sh 'curl -v GET http://${kafak_bridge_ingres}/healthy'
          
            }
        }
	
	
		 stage('6.1: Testing Create Topic customer') {
             steps {
	              
                  // list topic
                  sh 'kubectl get kt -n ${NAMESPACE} '
	          // create simple topic 
		  sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  6.1/customer-topic.yaml"
		  sh "sed -i 's|my-cluster|${kafka_cluster_name}|g'  examples/bridge/kafka-bridge-aia.yaml"
		  sh 'kubectl  apply -f  6.1/customer-topic.yaml'	  
		  // check topic customer
		  sh 'kubectl get kt -n ${NAMESPACE} |grep -i customer '
            
            }
        }
	
	
		 stage('6.2: Testing Create User') {
             steps {
	              
                // list  user
		sh 'kubectl get ku -n ${NAMESPACE} '
		// create user 
	        sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  6.2/kafka-user.yaml"
		sh "sed -i 's|my-cluster|${kafka_cluster_name}|g'  6.2/kafka-user.yaml"
		sh "sed -i 's|my-user|${user_kafka}|g'  6.2/kafka-user.yaml"
		sh 'kubectl apply -f  6.2/kafka-user.yaml || true'
		
		// check user 
		sh 'kubectl get ku -n ${NAMESPACE}'
		
            
            }
        }
	
	
		 stage('6.3: Testing Kafka User  auth https/ssl') {
             steps {
	              
                // Check  user chaiyapon with tls already exist
		sh 'kubectl get ku -n ${NAMESPACE} '
		
		// Extract and configure the user credentials
	        sh "sed -i 's|my-user|${user_kafka}|g' user-crt.sh"
		sh "sed -i 's|my-cluster|${kafka_cluster_name}|g' user-crt.sh"
		sh "sed -i 's|kafka-ingress|${kafk_bootstrap_name}|g' user-crt.sh"
		sh 'sh user-crt.sh '

	       
	       //Extract the cluster CA certificate and password
	      
              // sh 'kubectl get secret ${kafka_cluster_name}-cluster-ca-cert -o jsonpath='{.data.ca\.crt}'   -n ${NAMESPACE} | base64 --decode > 6.3/ca.crt '
              // sh 'kubectl get secret ${kafka_cluster_name}-cluster-ca-cert -o jsonpath='{.data.ca\.password}'   -n ${NAMESPACE} | base64 --decode > 6.3/ca.password '
	       
	       //Import it into truststore
	       
	      // sh 'export CERT_FILE_PATH=6.3/ca.crt'
	      // sh 'export CERT_PASSWORD_FILE_PATH=6.3/ca.password'
	     // sh 'export KEYSTORE_LOCATION=6.3/cacerts'
	     //  sh 'export PASSWORD=`cat $CERT_PASSWORD_FILE_PATH`'
	     //  sh 'keytool -importcert -alias strimzi-kafka-cert -file $CERT_FILE_PATH -keystore $KEYSTORE_LOCATION -keypass $PASSWORD -noprompt'
	       
	       
	      // Create properties file for Kafka CLI clients
	    //  sh 'touch  6.3/client-ssl-auth.properties'
	     // sh 'echo "bootstrap.servers=${kafk_bootstrap_name}" >> 6.3/client-ssl-auth.properties'
	    //  sh 'echo "security.protocol=SSL" >> 6.3/client-ssl-auth.properties'
	    //  sh 'echo "ssl.truststore.location=6.3/cacerts" >> 6.3/client-ssl-auth.properties'
	   //   sh 'echo "ssl.truststore.password=changeit" >> 6.3/client-ssl-auth.properties'
	   //   sh 'echo "ssl.keystore.location=6.3/kafka-auth-keystore.jks" >> 6.3/client-ssl-auth.properties'
	   //   sh 'echo "ssl.keystore.password=foobar" >> 6.3/client-ssl-auth.properties'   
	   //   sh 'echo "ssl.key.password=`cat  6.3/ca.password'" >> 6.3/client-ssl-auth.properties'

            
            }
        }
        
	

        

        
 
        
        

        
       
       
        
    }
   
}
      
