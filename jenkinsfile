pipeline {
    agent any
    
    parameters {
        gitParameter name: 'BRANCH_TAG', 
                     type: 'PT_BRANCH_TAG',
                     defaultValue: 'master'
    }
    
    
      environment {
     
        git_url = 'https://github.com/wintel-co-th/kafka-mfec-testcase.git'
        // AZURE RESOURCE
        AcrRegistry = 'wintelhub.azurecr.io'                        // acrth01seanshared01
        AcrRegistry_prod  = 'acrth01seapshared01'


        AZ_AKZ_USER = 'azure-chaiyapon'
        AZ_AKS_RESOUCE_GROUP = 'AKS-Cluster'
        
	 // AZURE AKS Cluster
        az_cluster_name = 'wintel'
        NAMESPACE = 'kafka'  
	
        // Kafka Cluster
        kafka_cluster_name = 'thdlcd3-uat-kafka-cluster'
	kafka_bootstrap_name = 'kafka-bootstrap.thdlcd3-uat.aiaazure.biz'
	
        // Kafka connect
        kafka_connect_name = 'thdlcd3-uat-connect-cluster'	
	
       	//Kafka bridge 

        kafak_bridge_ingres = 'kafka-bridge-thdlcd3-uat.aiaazure.biz'
	
	// authentication
	user_kafka = 'chaiyapon'
	
	// IP edge Node
	
	edge_ip = '20.205.169.228'
	
	

    }

  
    stages {
    
    
           stage('Azure Login'){
            steps {

                 withCredentials([azureServicePrincipal('azure-chaiyapon')]) {
                  sh 'az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET -t $AZURE_TENANT_ID' 
                  sh 'az account show'
            }
       }
    }
         
    
           stage('Get credentials Azure AKS'){
            steps {
                     
                     //cleanup current user k8s credentials
                    sh 'rm -rf   ~/.kube || true'
                    sh "echo ============ AKS Credential ==============="
                    sh "az aks get-credentials -n ${az_cluster_name} -g ${AZ_AKS_RESOUCE_GROUP}"
            }      
       }
    
   
		
		  stage('GitClone') {
              steps {
                script {
                    def scmInfo = checkout([
                        $class: 'GitSCM',
                        branches: [[name: '${BRANCH_TAG}']],
                        doGenerateSubmoduleConfigurations: false,
                        extensions: [],
                        submoduleCfg: [],
                        userRemoteConfigs: [
                            [credentialsId: 'git_credentials',
                            url: env.git_url]
                        ]
                    ])
                    
                }
            }
        }
	
	
	       stage('2.1: Testing Down Kafka Cluster') {
             steps {
                
		  sh "echo ============ capture Before Down ==============="
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  
		  sh "echo ============ Down kafk-0 ==============="
                  sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i kafka-0) -n ${NAMESPACE} || true'
		  
		  sh "echo ============  Pod are terminating and createing  ==============="
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  sh 'sleep 5m'
		  
		   sh "echo ============ Verify kafka-o up and running  ==============="
                   sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
  
  
   stage('2.2: Load Data to Topic') {
             steps {
                
                 sh "echo ============ Producer data to topic  ==============="
                 sh 'kubectl cp 2.2/insert.sh  ${kafka_cluster_name}-kafka-0:/home/kafka  -n ${NAMESPACE}'
                 sh 'kubectl cp 2.2/file01  ${kafka_cluster_name}-kafka-0:/home/kafka  -n ${NAMESPACE}'
                 sh 'kubectl exec ${kafka_cluster_name}-kafka-0  /home/kafka/insert.sh  -n ${NAMESPACE}'


            }
        }
  
  
   stage('2.3: Consumer Data from Topic') {
             steps {
                
                  sh "echo ============ Consumer data from topic  ==============="
      sh 'kubectl exec ${kafka_cluster_name}-kafka-0  -n ${NAMESPACE} -- bin/kafka-console-consumer.sh --bootstrap-server  localhost:9092  --topic topic-a --from-beginning --timeout-ms 10000'

            }
        }
  
  
     stage('3.1: Testing Down Zookeeper Cluster') {
             steps {
                
                  sh "echo ============ capture Before Down ==============="
                  sh 'kubectl get pods -n ${NAMESPACE} '
		  
		  sh "echo ============ Down zookeeper-0 ==============="
                  sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i zookeeper-0) -n ${NAMESPACE} || true'
		  
		  sh "echo ============ Pod are terminating and createing  ==============="
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  sh 'sleep 5m'
		  
		  sh "echo ============ Verify zookeeper-0 up and running  ==============="
                  sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
  
     stage('4.1: Testing Client API Connect to Kafka bridge') {
             steps {
                
		  sh "echo ============ List ingress  ==============="
                  sh 'kubectl get ingress -n ${NAMESPACE} '
		  
		  
		  sh "echo ============ List kafka bridge  ==============="
                  sh 'kubectl get pods -n ${NAMESPACE} | grep -i bridge'
		  
		  
		  sh "echo ============ Healthy check kafka bridge   ==============="
                  sh 'curl -v GET http://${kafak_bridge_ingres}/healthy'
          
            }
        }


        
   stage('5.1.1: Testing Connecter Load Data to JDBC Connect') {
             steps {

		  sh "echo ============  List connector  ==============="
                  sh 'kubectl get kctr -n ${NAMESPACE} '
		  
                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  5.1/jdbc/kafka-jdbc.yaml|| true"
                 sh "sed -i 's|my_connect_cluster|${kafka_connect_name}|g'  5.1/jdbc/kafka-jdbc.yaml|| true"
                 sh "sed -i 's|ip_edge|${edge_ip}|g'  5.1/jdbc/kafka-jdbc.yaml|| true"
                 //sh "cat  5.1/jdbc/kafka-jdbc.yaml|| true"

		 
		 sh "echo ============  create JDBC connector  ==============="
                 sh 'kubectl apply -f 5.1/jdbc/kafka-jdbc.yaml|| true'
                 sh 'sleep 5m'
		 

		sh "echo ============  verify jdbc connector ==============="
                 sh 'kubectl get kctr -n ${NAMESPACE} '
                  

            }
        }
  
     stage('5.1.2: Testing Connecter Load Data to File Connect') {
             steps {
                
   
		  sh "echo ============  List connector =============="
                  sh 'kubectl get kctr -n ${NAMESPACE} '


                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  5.1/file/file-topic.yaml|| true"
                 sh "sed -i 's|kafka-cluster|${kafka_cluster_name}|g' 5.1/file/file-topic.yaml|| true"
                 sh 'kubectl apply -f  5.1/file/file-topic.yaml|| true'
                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/' 5.1/file/kafka-file.yaml|| true"
                 sh "sed -i 's|my_connect_cluster|${kafka_connect_name}|g'  5.1/file/kafka-file.yaml|| true"
                 sh "cat  5.1/file/kafka-file.yaml|| true"
		 
		 

		   sh "echo ============   create File connector =============="
                  sh 'kubectl apply -f 5.1/file/kafka-file.yaml|| true'
                  sh 'sleep 5m'
		  
		  
		  sh "echo ============  Verify File connector =============="
                  sh 'kubectl get kctr -n ${NAMESPACE} '
                  
                  
            }
        }
  
   stage('5.1.3: Testing Connecter Load Data to CSV File') {
             steps {
                
                  sh "echo ============  List connector =============="
                  sh 'kubectl get kctr -n ${NAMESPACE} '


                  sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  5.1/csv/csv-topic.yaml|| true"
                  sh "sed -i 's|kafka-cluster|${kafka_cluster_name}|g'  5.1/csv/csv-topic.yaml|| true"
                  sh 'kubectl apply -f 5.1/csv/csv-topic.yaml|| true|| true'
      
                  sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/' 5.1/csv/kafka-csv.yaml|| true"
                  sh "sed -i 's|my_connect_cluster|${kafka_connect_name}|g' 5.1/csv/kafka-csv.yaml|| true"
                  sh "sed -i 's|ip_edge|${edge_ip}|g'  5.1/csv/kafka-csv.yaml|| true"
                  sh "cat  5.1/csv/kafka-csv.yaml|| true"
		  
		  

		   sh "echo ============  Create csv connector =============="
                  sh 'kubectl apply -f 5.1/csv/kafka-csv.yaml|| true'
                  sh 'sleep 5m'
		  
		   sh "echo ============  Verify csv connector =============="
                  sh 'kubectl get kctr -n ${NAMESPACE} '
                  

            }
        }
	
	
	
	   stage('5.1.4: Testing Connecter Debezium  SQL Server ') {
             steps {
                

		  

		   sh "echo ============  Create Debezium SQL Server connector =============="


            }
        }
	
	
        
  
  
     stage('6.1: Testing Create Topic customer') {
             steps {
                
		
		  sh "echo ============  List topic =============="
                  sh 'kubectl get kt -n ${NAMESPACE} '
		  
		  
		  sh "echo ============  Create customer topic  ==============" 
                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  6.1/customer-topic.yaml"
                 sh "sed -i 's|my-cluster|${kafka_cluster_name}|g'  6.1/customer-topic.yaml"
                 sh 'kubectl  apply -f  6.1/customer-topic.yaml'   
		 
		 
		 
		  sh "echo ============  Check topic customer  ==============" 
                 sh 'kubectl get kt -n ${NAMESPACE} |grep -i customer '
            
            }
        }
	
	
  
     stage('6.2: Testing Create User') {
             steps {
                

		 sh "echo ============  List  user =============="
                 sh 'kubectl get ku -n ${NAMESPACE} '
		 
		 sh "echo ============  Create user  =============="
                 sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  6.2/kafka-user.yaml"
                 sh "sed -i 's|my-cluster|${kafka_cluster_name}|g'  6.2/kafka-user.yaml"
                 sh "sed -i 's|my-user|${user_kafka}|g'  6.2/kafka-user.yaml"
                 sh 'kubectl apply -f  6.2/kafka-user.yaml || true'
                 sh 'sleep 1m'
		 
		 
		 
		 sh "echo ============  Check user   ${user_kafka}  =============="
                 sh 'kubectl get ku -n ${NAMESPACE}'
    
    
            
            }
        }
  
  
     stage('6.3: Testing Kafka User ${user_kafka}  auth https/ssl') {
             steps {
                

		 sh "echo ============  Check  user ${user_kafka}  with tls already exist =============="
                 sh 'kubectl get ku -n ${NAMESPACE} '
		 sh "echo ============   Extract and configure the user credentials =============="
                 sh "sed -i 's|my_user|${user_kafka}|g' kafka_user_auth.sh"
                 sh "sed -i 's|my_cluster|${kafka_cluster_name}|g' kafka_user_auth.sh"
                 sh "sed -i 's|kafka_nemspaces|${NAMESPACE}|g' kafka_user_auth.sh"
                 sh "sed -i 's|kafka_bootstrap|${kafka_bootstrap_name}|g' kafka_user_auth.sh"
                 sh 'sh kafka_user_auth.sh'
  
            }
        }
        
        
    

        

        
 
        
        

        
       
       
        
    }
   
}
      
