pipeline {
    agent any
    
    parameters {
        gitParameter name: 'BRANCH_TAG', 
                     type: 'PT_BRANCH_TAG',
                     defaultValue: 'master'
    }
    
    
      environment {
     
        git_url = 'https://github.com/wintel-co-th/kafka-uat-cd-mfec.git'
        // AZURE RESOURCE
        AcrRegistry = 'wintelhub.azurecr.io'                        // acrth01seanshared01
        AcrRegistry_prod  = 'acrth01seapshared01'


        AZ_AKZ_USER = 'azure-chaiyapon'
        AZ_AKS_RESOUCE_GROUP = 'AKS-Cluster'
        
	 // AZURE AKS Cluster
        az_cluster_name = 'wintel'
        NAMESPACE = 'kafka'  
	
        // Kafka Cluster
        kafka_cluster_name = 'thdlcd0-uat-kafka-cluster'
	
       	//Kafka bridge 

        kafak_bridge_ingres = 'kafka-bridge-thdlcd01-uat.aiaazure.biz'

    }

  
    stages {
    
    
           stage('Azure Login'){
            steps {

                 withCredentials([azureServicePrincipal('azure-chaiyapon')]) {
                  sh 'az login --service-principal -u $AZURE_CLIENT_ID -p $AZURE_CLIENT_SECRET -t $AZURE_TENANT_ID' 
                  sh 'az account show'
            }
       }
    }
         
    
           stage('Get credentials Azure AKS'){
            steps {
                     
                     //cleanup current user k8s credentials
                    sh 'rm -rf   ~/.kube || true'
                    sh "echo ============ AKS Credential ==============="
                    sh "az aks get-credentials -n ${az_cluster_name} -g ${AZ_AKS_RESOUCE_GROUP}"
            }      
       }
    
   
		
		  stage('GitClone') {
              steps {
                script {
                    def scmInfo = checkout([
                        $class: 'GitSCM',
                        branches: [[name: '${BRANCH_TAG}']],
                        doGenerateSubmoduleConfigurations: false,
                        extensions: [],
                        submoduleCfg: [],
                        userRemoteConfigs: [
                            [credentialsId: 'git_credentials',
                            url: env.git_url]
                        ]
                    ])
                    
                }
            }
        }
		
		 stage('2.1: Testing Down Kafka Cluster') {
             steps {
	              
                  // capture Before Down
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  // Down kafk-0
                  sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i kafka-0) || true'
                  // Pod are terminating and createing 
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  sh 'sleep 5m'
                  // Verify kafka-o up and running
                   sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
        
        
    	 stage('2.1: Testing Down Kafka Cluster') {
             steps {
	              
                  // capture Before Down
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  // Down kafk-0
                  sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i kafka-0) || true'
                  // Pod are terminating and createing 
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  sh 'sleep 5m'
                  // Verify kafka-o up and running
                   sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
	
	
	 stage('2.2: Load Data to Topic') {
             steps {
	              
                  // copy scrip insert 
		  sh 'kubcetl cp 2.2/insert.sh  ${kafka_cluster_name}-kafka-0:/home/kafka  -n ${NAMESPACE}'
		  sh 'kubcetl cp 2.2/file01  ${kafka_cluster_name}-kafka-0:/home/kafka  -n ${NAMESPACE}'
		  sh 'kubectl exec ${kafka_cluster_name}-kafka-0  /home/kafka/insert.sh  -n ${NAMESPACE}'


            }
        }
	
	
	 stage('2.3: Consumer Data from Topic') {
             steps {
	              
                  // Consumer
		  sh 'kubectl exec ${kafka_cluster_name}-kafka-0  -n ${NAMESPACE} -- bin/kafka-console-consumer.sh --bootstrap-server  localhost:9092  --topic topic-a --from-beginning --timeout-ms 10000'

            }
        }
	
	
		 stage('3.1: Testing Down Zookeeper Cluster') {
             steps {
	              
                  // capture Before Down
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  // Down zookeeper-0
                  sh 'kubectl delete $( kubectl get pods -o name -n kafka |grep -i zookeeper-0) || true'
                  // Pod are terminating and createing 
                  sh 'kubectl get pods -n ${NAMESPACE} '
                  sh 'sleep 5m'
                  // Verify zookeeper-0 up and running
                  sh 'kubectl get pods -n ${NAMESPACE} '

            }
        }
	
		 stage('4.1: Testing Client API Connect to Kafka bridge') {
             steps {
	              
                  // list ingress
                  sh 'kubectl get ingress -n ${NAMESPACE} '
		  // list kafka bridge
		  sh 'kubectl get pods -n ${NAMESPACE} | grep -i bridge'
		  // healthy check kafka bridge  
		  sh 'curl -v GET http://${kafak_bridge_ingres}/healthy'
          
            }
        }
	
	
		 stage('6.1: Testing Create Topic customer') {
             steps {
	              
                  // list topic
                  sh 'kubectl get kt -n ${NAMESPACE} '
	          // create simple topic 
		  sh "sed -i 's/namespace: .*/namespace: ${NAMESPACE}/'  6.1/customer-topic.yaml"
		  sh "sed -i 's|my-cluster|${kafka_cluster_name}|g'  examples/bridge/kafka-bridge-aia.yaml"
		  sh 'kubectl  apply -f  6.1/customer-topic.yaml'	  
		  // check topic ustomer
		  sh 'kubectl get kt -n ${NAMESPACE} |grep -i customer '
            
            }
        }
	
        
	

        

        
 
        
        

        
       
       
        
    }
   
}
      
